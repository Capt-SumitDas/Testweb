WEBVTT

00:00:01.732 --> 00:00:03.766
Inspecting Sitemaps

00:00:04.561 --> 00:00:07.533
Web applications can include sitemap files

00:00:07.533 --> 00:00:11.833
to help search engine bots
crawl and index their sites.

00:00:12.387 --> 00:00:16.533
These files also include directives
of which URLs not to crawl.

00:00:17.240 --> 00:00:21.100
These are usually sensitive pages
or administrative consoles

00:00:21.100 --> 00:00:24.266
exactly the sort of pages we are interested in.

00:00:30.279 --> 00:00:37.500
The two most common sitemap filenames
are robots.txt and sitemap.xml.

00:00:39.557 --> 00:00:43.233
For example, we can retrieve
the robots.txt file from

00:00:43.233 --> 00:00:47.533
www.google.com with curl.

00:00:49.558 --> 00:00:53.133
Allow and Disallow are
directives for web crawlers

00:00:53.133 --> 00:00:55.466
indicating pages or directories that

00:00:55.466 --> 00:01:00.400
“polite” web crawlers may
or may not access, respectively.

00:01:03.942 --> 00:01:07.666
Although the listed pages and
directories may not be interesting

00:01:07.666 --> 00:01:10.033
and some may even be invalid,

00:01:10.033 --> 00:01:13.000
sitemap files should not be overlooked

00:01:13.000 --> 00:01:16.266
as they may contain clues
about the website layout

00:01:16.266 --> 00:01:18.633
or other interesting information.
